<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Point Prompting: Counterfactual Tracking with Video Diffusion Models">
  <meta name="keywords" content="Video Diffusion Models, Tracking, Tracking any point, Diffusion, Correspondences, Matching, Video generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Point Prompting: Counterfactual Tracking with Video Diffusion Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-131271936-1', 'auto');
    ga('send', 'pageview');

  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="/static/nerfies/css/bulma.min.css">
  <!-- <link rel="stylesheet" href="/static/nerfies/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="/static/nerfies/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="/static/nerfies/css/index.css">
  <link rel="icon" href="/static/point-prompting/imgs/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  
  <!-- <script src="/static/nerfies/js/bulma-carousel.min.js"></script> -->
  <!-- <script src="/static/nerfies/js/bulma-slider.min.js"></script> -->
  <script src="/static/nerfies/js/index.js"></script>
  <style>
    /* Minimal styles for interactive before/after slider */
    .slider-container {
      position: relative;
      width: 100%;
      overflow: hidden;
      border-radius: 8px;
      box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
    }
    .slider-video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      /* height: 100%; */
      object-fit: cover;
      pointer-events: none;
    }
    .slider-image.right {
      clip-path: polygon(75% 0, 100% 0, 100% 100%, 75% 100%);
    }
    .slider-handle {
      position: absolute;
      top: 0;
      left: 75%;
      width: 4px;
      height: 100%;
      background: rgba(255, 255, 255, 0.7);
      cursor: ew-resize;
      transform: translateX(-50%);
      z-index: 10;
    }
    .slider-handle::after {
      content: '↔';
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: 32px;
      height: 32px;
      background: rgba(255, 255, 255, 0.9);
      color: #111827;
      border-radius: 9999px;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 14px;
      font-weight: 700;
    }
    video.responsive-video {
      width: 100%;
      height: auto;
      object-fit: contain;
      border-radius: 8px;
      display: block;
      margin-left: auto;
      margin-right: auto;
      background-color: transparent;
      box-shadow: none;
      /* border: 0; */
      /* vertical-align: top; */
    }
    video.responsive-video-2 {
      width: 100%;
      max-height: 480px;
      height: auto;
      object-fit: cover;
      border-radius: 8px;
      display: block;
      margin-left: auto;
      margin-right: auto;
    }
    video.responsive-video-3 {
      width: 100%;
      /* max-height: 500px; */
      height: auto;
      object-fit: contain;
      border-radius: 8px;
      display: block;
      margin-left: auto;
      margin-right: auto;
      background-color: transparent;
    }
    .video-bordered {
      border: 2px solid #c2c2c2;
      border-radius: 8px;
      /* margin: 0.5rem auto; */
      padding: 0.5rem;
    }
    .video-corner-cropped {
      border-radius: 8px;
    }
  /* Reduce slider height and ensure videos fill capped container */
  .slider-container { 
    aspect-ratio: 21/9; 
    max-height: 900px; 
  }
  .slider-container-gen-videos { 
    max-height: 1200px; 
    max-width: 1800px;
  }
    .slider-container .slider-video { height: 100%; }
  /* Widen content containers for sections, but keep hero/title at default width */
  section.section .container.is-max-desktop {
    max-width: 1400px;
  }
  .no-shadow { box-shadow: none !important; border: 0 !important; background: transparent !important; overflow: hidden; line-height: 0; }
  .video-crop-bottom { clip-path: inset(0 0 10px 0); }
  /* Scoped slider styles from CMRW */
  .slider-section { overflow: hidden; }
  .slider-section .slider-container {
    position: relative;
    width: 100%;
    max-width: 1300px;
    margin: 0 auto;
    overflow: hidden;
    height: auto;
    min-height: unset;
    display: flex;
    align-items: center;
    justify-content: center;
    left: 0;
    transform: none;
    max-height: 1500px;
  }
  .slider-section .slider { display: flex; transition: transform 0.5s ease-in-out; width: 100%; }
  .slider-section .slide { flex: 0 0 100%; min-width: 100%; box-sizing: border-box; display: flex; justify-content: center; align-items: center; height: 100%; }
  .slider-section .grid1x1-depth { display: grid; grid-template-columns: 1fr; grid-template-rows: 1fr; gap: 16px; width: 100%; max-width: 1100px; height: 100%; margin: 0 auto; }
  .slider-section .grid1x1-small { display: grid; grid-template-columns: 1fr; grid-template-rows: 1fr; gap: 16px; width: 100%; max-width: 1000px; height: 100%; margin: 0 auto; }
  .slider-section .grid2x2 { display: grid; grid-template-columns: 1fr 1fr; grid-template-rows: 1fr 1fr; gap: 16px; width: 100%; max-width: 1250px; height: 100%; margin: 0 auto; }
  .slider-section .grid3x3 { display: grid; grid-template-columns: repeat(3, 1fr); grid-template-rows: repeat(3, 1fr); gap: 16px; width: 100%; max-width: 1200px; height: 100%; margin: 0 auto; }
  .slider-section .video-with-label { display: flex; flex-direction: column; height: 100%; width: 100%; }
  .slider-section .video-with-label video { width: 100%; height: 100%; max-height: 100%; object-fit: contain; background: #eee; display: block; }
  .slider-section .video-label { width: 100%; text-align: center; font-size: 1rem; color: #222; background: rgba(255,255,255,0.85); padding: 4px 0 2px 0; height: 15%; box-sizing: border-box; overflow: hidden; text-overflow: ellipsis; white-space: nowrap; }
  .slider-section .slider-button { position: absolute; top: 50%; transform: translateY(-50%); background: rgba(0, 0, 0, 0.5); color: white; padding: 16px 12px; border: none; cursor: pointer; font-size: 18px; transition: background 0.3s; z-index: 3; }
  .slider-section .slider-button:hover { background: rgba(0, 0, 0, 0.8); }
  .slider-section .prev { left: 0; }
  .slider-section .next { right: 0; }
  .slider-section .slider-dots { display: flex; justify-content: center; align-items: center; margin: 18px 0 0 0; gap: 10px; }
  .slider-section .slider-dot { width: 12px; height: 12px; border-radius: 50%; background: #bbb; opacity: 0.5; transition: background 0.3s, opacity 0.3s; cursor: pointer; }
  .slider-section .slider-dot.active { background: #222; opacity: 1; }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Point Prompting: Counterfactual Tracking with Video Diffusion Models</h1>
          <div class="is-size-5 publication-authors">
            <!-- # Ayush Shrivastava*, Sanyam Mehta*, Daniel Geng, Andrew Owens -->
            <span class="author-block">
              <a href="https://ayshrv.com">Ayush Shrivastava</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://sanyam-mehta.github.io/about-me">Sanyam Mehta</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://dangeng.github.io">Daniel Geng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="http://andrewowens.com">Andrew Owens</a><sup>1,2</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Michigan,</span>
            <span class="author-block"><sup>2</sup>Cornell University</span>
          </div>
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">CVPR 2025</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2510.11715"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.11715"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/ayshrv/cmrw"
                   target="_blank"
                   rel="noopener"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <span class="link-block">
                <a href="#bibtex"
                   class="external-link button is-normal is-rounded is-dark">
                  <!-- <span class="icon">
                      <i class="fas fa-quote-right"></i>
                  </span> -->
                  <span class="icon">
                    <svg class="svg-inline--fa fa-book fa-w-14" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="book" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z" data-darkreader-inline-fill="" style="--darkreader-inline-fill: currentColor;"></path></svg><!-- <i class="fas fa-book"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>BibTeX</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" style="padding-top: 0rem;">
  <div class="container is-max-desktop">

    <div class="column is-gapless is-centered " style="width: 80%; margin-left: auto; margin-right: auto;">
      <h1 class="subtitle is-5 has-text-centered">
        <b>TL;DR:</b> We propose a method to do zero-shot point tracking by simply prompting video diffusion models to visually mark points as they move over time.
      </h1>
    </div>

    <br><br>
    
      <div class="column is-12 is-centered">
            <figure class="image">
                <video class="responsive-video" autoplay muted loop playsinline style="width: 90%; height: auto; object-fit: contain;">
                  <source src="/static/point-prompting/videos/teaser.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
            </figure>
      </div>
      <div class="column is-gapless" style="padding-top: 0rem; margin-top: 0rem;">
        <p class="subtitle is-6 has-text-centered" style="font-size: 1.1em;">
          These videos are directly generated by the video diffusion model, with red markers propagated across time.
        </p>
      </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-three-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified" style="font-size: 1.1em;">
          <p>
            Trackers and video generators solve closely related problems: the former analyze motion, while the latter synthesize it. We show that this connection enables pretrained video diffusion models to perform zero-shot point tracking by simply prompting them to visually mark points as they move over time. We place a distinctively colored marker at the query point, then regenerate the rest of the video from an intermediate noise level. This propagates the marker across frames, tracing the point's trajectory. To ensure that the marker remains visible in this counterfactual generation, despite such markers being unlikely in natural videos, we use the unedited initial frame as a negative prompt. Through experiments with multiple image-conditioned video diffusion models, we find that these "emergent" tracks outperform those of prior zero-shot methods and persist through occlusions, often obtaining performance that is competitive with specialized self-supervised models.
        </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Point Propagation</h2>
    <div class="column is-12 is-centered">
      <figure class="video-bordered" style="width: 90%; margin: 0 auto;">
          <video class="responsive-video video-crop-bottom" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/point_propagation.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
      </figure>
      <br/>
      <p class="subtitle is-6 has-text-centered" style="width: 80%; margin: 0 auto; font-size: 1.1em;">
        We mark a query point in the first frame with a colored dot. Then, using SDEdit, we guide the diffusion model to regenerate the video, propagating the dot across subsequent frames, by enhancing the counterfactual signal. The regenerated video propagates the marker across frames, tracing the underlying point's trajectory.
      </p>
    </div>

    <h2 class="title is-4 has-text-centered" style="margin-top: 3rem;">Enhancing the Counterfactual Signal</h2>
    <div class="column is-12 is-centered">
      <figure class="image" style="width: 90%; margin: 0 auto;">
        <img src="/static/point-prompting/imgs/counterfactual-enhance.png">
      </figure>
      <br/>
      <p class="subtitle is-6 has-text-centered" style="width: 80%; margin: 0 auto; font-size: 1.1em;">
        We use negative prompting to ensure that the generated video contains the marker. In each denoising step, we condition the denoising on two images: (1) <b>Edited First Frame</b>: the first frame of the video with a marking added, and (2) <b>Unedited First Frame</b>: the original first frame of the video. We then subtract the weighted noise vector of the latter from the former which enhances the counterfactual signal.
      </p>
    </div>

  </div>

</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="content">
        <h2 class="title is-3">Qualitative Results</h2>
        <p class="mb-6"></p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="content">
        <h2 class="title is-4">Point Propagation</h2>
        <!-- Any description here -->
      </div>
    </div>
    <div class="columns is-centered">
      <div class="content">
      <p class="is-6 has-text-centered" style="margin-bottom: 0.5rem; margin-top: 0.5rem; font-size: 1.1em;">
      These generated videos show a propagated <span style="color: red;">red marker</span> across time. The video model used here is <b>Wan2.1 14B I2V</b>.
      </p>
      </div>
    </div>
    <div class="slider-section" id="gen_videos_slider" >
      <div class="slider-container-gen-videos">
        <div class="slider">
          
          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/bike-packing_batch_0.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/bmx-trees_batch_5.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/parkour_batch_17.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/india_batch_5.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/blackswan_batch_4.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/car-roundabout_batch_15.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/dogs-jump_batch_5.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/soapbox_batch_1.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/kite-surf_batch_0.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/horsejump-high_batch_1.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/gold-fish_batch_22.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/car-shadow_batch_17.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/camel_batch_6.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/paragliding-launch_batch_20.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/drift-straight_batch_0.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/dog_batch_2.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/shooting_batch_2.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/lab-coat_batch_0.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/libby_batch_15.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/gen_videos/cows_batch_3.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          
        </div>
        <button class="slider-button prev">❮</button>
        <button class="slider-button next">❯</button>
      </div>
      <!-- <p style="text-align: center; ">(Frame transition: 1.5 sec)</p> -->
      <div class="slider-dots"></div>
    </div>
  </div>
</section>

    
    
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="content">
        <h2 class="title is-4">Tracking</h2>
        <!-- Any description here -->
      </div>
    </div>

    <div class="columns is-centered">
      <div class="content">
      <p class="is-6 has-text-centered" style="margin-bottom: 0.5rem; margin-top: 0.5rem; font-size: 1.1em;">
      We run a color-based tracker on generated videos to get the track for a propagated point. We combine the tracks for all propagated points and show it here.
      </p>
      </div>
    </div>
  
    <div class="slider-section" id="tracking_videos_slider" >
      <div class="slider-container-gen-videos">
        <div class="slider">
          
          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/horsejump-high_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/bike-packing_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/india_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/soapbox_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/bmx-trees_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/dogs-jump_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/drift-chicane_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/gold-fish_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/car-roundabout_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/dog_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/goat_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/loading_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <div class="slide">
            <div class="grid2x2">
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/blackswan_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/car-shadow_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/cows_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
              <div>
                <video class="video-corner-cropped" autoplay muted loop playsinline>
                  <source src="/static/point-prompting/videos/tracks/kite-surf_tracks_tails.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          
        </div>
        <button class="slider-button prev">❮</button>
        <button class="slider-button next">❯</button>
      </div>
      <!-- <p style="text-align: center; ">(Frame transition: 1.5 sec)</p> -->
      <div class="slider-dots"></div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4 has-text-centered">Tracking Through Occlusions</h2>
    <div class="columns is-multiline is-variable is-3 is-centered" style="margin-top: 1rem; width: 80%; margin-left: auto; margin-right: auto;">
      <div class="column is-full">
        <div class="slider-container">
          <video class="slider-video left" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/india_tracks_tails.mp4" type="video/mp4">
          </video>
          <video class="slider-video right slider-image" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/india.mp4" type="video/mp4">
          </video>
          <div class="slider-handle"></div>
        </div>
      </div>
      <div class="column is-full">
        <div class="slider-container">
          <video class="slider-video left" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/bmx-trees_tracks_tails.mp4" type="video/mp4">
          </video>
          <video class="slider-video right slider-image" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/bmx-trees.mp4" type="video/mp4">
          </video>
          <div class="slider-handle"></div>
        </div>
      </div>
    </div>
    <p class="has-text-grey has-text-centered" style="margin-top: 0.75rem;">Drag the slider on the videos to compare our tracking results with the original video.</p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="content">
        <h2 class="title is-3">Failure Cases</h2>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="content">
      <p class="is-6 has-text-centered" style="margin-bottom: 0.5rem; margin-top: 0.5rem;">
      These generated videos show failure cases of our method.
      </p>
      </div>
    </div>
    <div class="slider-section" id="failure_videos">
      <div class="grid2x2">
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/failure_cases/cows_batch_4.mp4" type="video/mp4">
          </video>
          <p class="has-text-centered" style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <b>Stationary Point</b>: Point remains stationary with respect to the image boundaries.
          </p>
        </div>
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/failure_cases/parkour_batch_1.mp4" type="video/mp4">
          </video>
          <p class="has-text-centered" style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <b>Symmetry</b>: Point drawn on the right foot gets propagated to the left foot.
          </p>
        </div>
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/failure_cases/lab-coat_batch_10.mp4" type="video/mp4">
          </video>
          <p class="has-text-centered" style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <b>Propagation Failure</b>: Model fails to propagate the point in the last few frames.
          </p>
        </div>
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/failure_cases/horsejump-high_batch_20.mp4" type="video/mp4">
          </video>
          <p class="has-text-centered" style="margin-top: 0.5rem; margin-bottom: 0.5rem;">
            <b>Ambiguity Near Edges</b>: Point near the boundary snaps to background.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="content">
        <h2 class="title is-3">Point Propagation (with CogVideoX)</h2>
      </div>
    </div>
    
    <div class="slider-section" id="cogvideox_videos">
      <div class="grid2x2">
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/cogvideo/blackswan_batch_0.mp4" type="video/mp4">
          </video>
        </div>
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/cogvideo/india_batch_2.mp4" type="video/mp4">
          </video>
        </div>
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/cogvideo/car-shadow_batch_10.mp4" type="video/mp4">
          </video>
        </div>
        <div>
          <video class="video-corner-cropped" autoplay muted loop playsinline>
            <source src="/static/point-prompting/videos/cogvideo/horsejump-high_batch_2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>  

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="content">
        <h2 class="title is-3">Related Work</h2>
        <!-- Any description here -->
      </div>

    </div>
        <div class="columns is-centered">
        <div class="column is-centered is-four-fifths" style="font-size: 1.1em;">
          <ol>
            <li>
              <a href="https://diffusionfeatures.github.io/" target="_blank">DIFT: Emergent Correspondence
              from Image Diffusion</a>
              extracts features from a pretrained image diffusion model for matching points in images.</li>
            <li>
              <a href="https://neuroailab.github.io/opt_cwm_page/" target="_blank">Opt-CWM: Self-Supervised Learning of Motion Concepts by Optimizing Counterfactuals</a> inspires our counterfactual enchancement technique. This work learns RGB permutations that can be propagated through a frozen next-frame predictor, optimizing them with a jointly trained sparse optical-flow module, to enable temporal correspondence. 
              </li>
            
            <li>We evaluate two video diffusion models, <a href="https://arxiv.org/abs/2503.20314" target="_blank">Wan2.1</a> and <a href="https://arxiv.org/abs/2408.06072" target="_blank">CogVideoX</a>, both image-conditioned transformer models for video generation trained using Flow Matching.</li>

            <li>
              A recent concurrent work, 
              <a href="https://cvlab-kaist.github.io/DiffTrack/" target="_blank">Emergent Temporal Correspondences from Video Diffusion Transformers</a>, 
              extracts features from a pretrained video model for tracking,
              using a one-to-one frame-to-latent mapping to avoid temporal compression. However, it requires architecture-specific analysis to identify effective layers and does not address occlusions.
            </li>
              <li>
                Another concurrent work, <a href="https://neuroailab.github.io/projects/kl_tracing/" target="_blank">Taming generative video models for zero-shot optical flow extraction</a>, uses a generative video model to trace an injected perturbation across the predicted next frame for optical flow estimation and point tracking.
              </li>
          </ol>
        </div>
      </div>
    </div>
    
  </div>
</section>



<section class="section is-centered" id="bibtex" style="width: 1000px; margin-left: auto; margin-right: auto; font-size: 1.1em;">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{shrivastava2025pointprompting,
      title     = {Point Prompting: Counterfactual Tracking with Video Diffusion Models},
      author    = {Shrivastava, Ayush and Mehta, Sanyam and Geng, Daniel and Owens, Andrew},
      booktitle = {arXiv},
      year      = {2025},
      url       = {https://arxiv.org/abs/2510.11715},
}
      
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>,
            and is written by <a href="https://keunhong.com/">Keunhong Park</a> for the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project. You are free to use the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website, but please keep these links in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  // Simple before/after slider interaction
  // Simple before/after slider interaction (unchanged)
  document.addEventListener('DOMContentLoaded', function () {
    var sliders = document.querySelectorAll('.slider-container');
    sliders.forEach(function (slider) {
      var handle = slider.querySelector('.slider-handle');
      var rightImage = slider.querySelector('.slider-image.right');
      if (!handle || !rightImage) return;
      var isDragging = false;
      // Set default position to 75%
      handle.style.left = '75%';
      rightImage.style.clipPath = 'polygon(75% 0, 100% 0, 100% 100%, 75% 100%)';
      function startDrag() { isDragging = true; slider.classList.add('dragging'); }
      function stopDrag() { isDragging = false; slider.classList.remove('dragging'); }
      function onDrag(e) {
        if (!isDragging) return;
        var rect = slider.getBoundingClientRect();
        var clientX = (e.touches && e.touches[0]) ? e.touches[0].clientX : e.clientX;
        var x = clientX - rect.left;
        x = Math.max(0, Math.min(x, rect.width));
        var percent = (x / rect.width) * 100;
        handle.style.left = percent + '%';
        rightImage.style.clipPath = 'polygon(' + percent + '% 0, 100% 0, 100% 100%, ' + percent + '% 100%)';
      }
      handle.addEventListener('mousedown', startDrag);
      handle.addEventListener('touchstart', startDrag, { passive: true });
      document.addEventListener('mouseup', stopDrag);
      document.addEventListener('touchend', stopDrag, { passive: true });
      document.addEventListener('mousemove', onDrag);
      document.addEventListener('touchmove', onDrag, { passive: true });
    });
  });

  // Slider initializer copied from CMRW snippet
  function initSlider(sliderSection) {
    const slider = sliderSection.querySelector('.slider');
    const slides = sliderSection.querySelectorAll('.slide');
    const prevBtn = sliderSection.querySelector('.slider-button.prev');
    const nextBtn = sliderSection.querySelector('.slider-button.next');
    const dotsContainer = sliderSection.querySelector('.slider-dots');
    if (!slider || !slides.length || !prevBtn || !nextBtn || !dotsContainer) return;
    let currentSlide = 0;
    const totalSlides = slides.length;
    // Rely on CSS for widths; don't set inline width on slider or slides
    // Allow per-section button text customization
    const prevText = sliderSection.getAttribute('data-prev-text');
    const nextText = sliderSection.getAttribute('data-next-text');
    if (prevText) prevBtn.textContent = prevText;
    if (nextText) nextBtn.textContent = nextText;
    dotsContainer.innerHTML = '';
    for (let i = 0; i < totalSlides; i++) {
      const dot = document.createElement('div');
      dot.className = 'slider-dot' + (i === 0 ? ' active' : '');
      dot.addEventListener('click', () => { currentSlide = i; updateSlider(); });
      dotsContainer.appendChild(dot);
    }
    function updateSlider() {
      slider.style.transform = `translateX(-${currentSlide * 100}%)`;
      const dots = dotsContainer.querySelectorAll('.slider-dot');
      dots.forEach((dot, idx) => { dot.classList.toggle('active', idx === currentSlide); });
    }
    prevBtn.addEventListener('click', () => { currentSlide = (currentSlide - 1 + totalSlides) % totalSlides; updateSlider(); });
    nextBtn.addEventListener('click', () => { currentSlide = (currentSlide + 1) % totalSlides; updateSlider(); });
  }

  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('.slider-section').forEach(initSlider);
    // Delay-start videos: pause initially, then play after specified delay
    var delayedVideos = document.querySelectorAll('video[data-delay-start]');
    delayedVideos.forEach(function(v){
      var delayMs = parseInt(v.getAttribute('data-delay-start') || '1000', 10);
      // Ensure we start paused at first frame
      v.pause();
      v.currentTime = 0;
      setTimeout(function(){ v.play().catch(function(){}); }, delayMs);
    });
  });
  </script>

</body>
</html>
